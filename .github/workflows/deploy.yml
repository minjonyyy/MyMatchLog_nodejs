name: Deploy to Production

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    environment: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json

      - name: Install dependencies
        run: |
          cd backend
          npm ci

      - name: Build application
        run: |
          cd backend
          npm run lint
          npm run format:check
          echo "Build completed successfully"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ secrets.AWS_ECR_REPOSITORY }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG ./backend
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:latest ./backend
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Deploy to EC2
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USERNAME }}
          key: ${{ secrets.EC2_KEY_NAME }}
          script: |
            # Update system packages
            sudo apt-get update

            # Install Docker if not installed
            if ! command -v docker &> /dev/null; then
              echo "Installing Docker..."
              sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release
              curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
              echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
              sudo apt-get update
              sudo apt-get install -y docker-ce docker-ce-cli containerd.io
              sudo usermod -aG docker $USER
            fi

            # Fix Docker permissions
            sudo usermod -aG docker $USER
            sudo systemctl start docker
            sudo systemctl enable docker

            # Install Docker Compose if not installed
            if ! command -v docker-compose &> /dev/null; then
              echo "Installing Docker Compose..."
              sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
              sudo chmod +x /usr/local/bin/docker-compose
            fi

            # Install AWS CLI if not installed
            if ! command -v aws &> /dev/null; then
              echo "Installing AWS CLI..."
              sudo apt-get install -y unzip
              curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
              unzip awscliv2.zip
              sudo ./aws/install
              rm -rf aws awscliv2.zip
            fi

            # Install Node.js and PM2 if not installed
            if ! command -v node &> /dev/null; then
              echo "Installing Node.js..."
              curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
              sudo apt-get install -y nodejs
            fi

            if ! command -v pm2 &> /dev/null; then
              echo "Installing PM2..."
              sudo npm install -g pm2
            fi

            # Create application directory
            sudo mkdir -p /opt/mymatchlog
            sudo chown $USER:$USER /opt/mymatchlog
            cd /opt/mymatchlog

            # Configure AWS credentials
            export AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            export AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            export AWS_DEFAULT_REGION=${{ secrets.AWS_REGION }}

            # Login to ECR
            echo "Logging in to ECR..."
            aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | sudo docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}

            # Create docker-compose.yml
            cat > docker-compose.yml << 'EOF'
            version: '3.8'
            services:
              app:
                image: ${{ steps.build-image.outputs.image }}
                container_name: mymatchlog-api
                restart: unless-stopped
                ports:
                  - "3000:3000"
                environment:
                  - NODE_ENV=production
                  - DB_HOST=${{ secrets.DB_HOST }}
                  - DB_USER=${{ secrets.DB_USER }}
                  - DB_PASSWORD=${{ secrets.DB_PASSWORD }}
                  - DB_NAME=${{ secrets.DB_NAME }}
                  - DB_PORT=3306
                  - REDIS_HOST=${{ secrets.REDIS_HOST }}
                  - REDIS_PORT=6379
                  - ACCESS_TOKEN_SECRET_KEY=${{ secrets.ACCESS_TOKEN_SECRET_KEY }}
                  - REFRESH_TOKEN_SECRET_KEY=${{ secrets.REFRESH_TOKEN_SECRET_KEY }}
                  - ACCESS_TOKEN_EXPIRES_IN=15m
                  - REFRESH_TOKEN_EXPIRES_IN=7d
                  - AWS_ACCESS_KEY=${{ secrets.AWS_ACCESS_KEY_ID }}
                  - AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
                  - AWS_S3_REGION=${{ secrets.AWS_REGION }}
                  - AWS_S3_BUCKET_NAME=${{ secrets.AWS_S3_BUCKET_NAME }}
                  - PORT=3000
                healthcheck:
                  test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
                  interval: 30s
                  timeout: 10s
                  retries: 3
            EOF

            # Stop and remove existing containers (safe way)
            sudo docker-compose stop || true
            sudo docker-compose rm -f || true

            # Pull latest image and start
            sudo docker-compose pull
            sudo docker-compose up -d

            # Wait for application to start
            sleep 30

            # Run database migrations
            echo "Running database migrations..."
            sudo docker-compose exec -T app npm run migrate || echo "Migration failed, but continuing..."

            # Run database seeding
            echo "Running database seeding..."
            sudo docker-compose exec -T app npm run seed || echo "Seeding failed, but continuing..."

            # Check application health
            if curl -f http://localhost:3000/api/health; then
              echo "Application deployed successfully!"
              
              # Test database connection
              echo "Testing database connection..."
              if curl -f http://localhost:3000/api/teams; then
                echo "Database connection successful!"
              else
                echo "Database connection failed. Check RDS security group settings."
              fi
            else
              echo "Application deployment failed!"
              sudo docker-compose logs
              exit 1
            fi
